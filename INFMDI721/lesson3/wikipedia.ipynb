{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_link(url):\n",
    "    \"\"\"\n",
    "    Returns the first wikipedia link found in the current page\n",
    "    \"\"\"\n",
    "    link = None\n",
    "\n",
    "    content = requests.get(url)\n",
    "    soup = BeautifulSoup(content.text, features=\"html.parser\")\n",
    "    \n",
    "    #  Select text paragraphs\n",
    "    paragraphs = soup.select(\"p\")\n",
    "    for p in paragraphs:\n",
    "        x = p.find(\"a\")\n",
    "        if x:\n",
    "            link = x.get('href')\n",
    "            break\n",
    "            \n",
    "    if link:\n",
    "        # build full url\n",
    "        link = urllib.parse.urljoin('https://en.wikipedia.org/', link)\n",
    "\n",
    "    return link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_urls(url_start, url_stop, max_iter=25):\n",
    "    \"\"\"\n",
    "    Builds the chain of urls.\n",
    "    \"\"\"\n",
    "    urls = []\n",
    "\n",
    "    flag_remove_first = False\n",
    "    if 'Special:Random' in url_start:\n",
    "        flag_remove_first = True\n",
    "\n",
    "    urls.append(url_start)\n",
    "\n",
    "    while True:\n",
    "        # find next link\n",
    "        link = find_link(urls[-1])\n",
    "        if not link:\n",
    "            urls = None\n",
    "            break\n",
    "\n",
    "        urls.append(link)\n",
    "        \n",
    "        if urls[-1] == url_stop:\n",
    "            if flag_remove_first:\n",
    "                urls.pop(0) \n",
    "            print(\"distance between {} and {} is {}\".format(urls[0], urls[-1], len(urls)))\n",
    "            break\n",
    "        elif len(urls) > max_iter:\n",
    "            if flag_remove_first:\n",
    "                urls.pop(0) \n",
    "            print(\"STOP!!! The search {} and {} is too long ({} iter.)!\".format(urls[0],\n",
    "                                                                                url_stop,\n",
    "                                                                                max_iter))\n",
    "            break\n",
    "        elif link in urls[:-1]:\n",
    "            print(\"STOP!! We are looping. We pass twice in {}\".format(link))\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "                 \n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are looping, STOP!\n",
      "distance between https://en.wikipedia.org/wiki/Special:Random and https://en.wikipedia.org/wiki/India is 10\n",
      "We are looping, STOP!\n",
      "distance between https://en.wikipedia.org/wiki/Special:Random and https://en.wikipedia.org/wiki/India is 9\n",
      "The search is too long, STOP!\n",
      "distance between https://en.wikipedia.org/wiki/Special:Random and https://en.wikipedia.org/wiki/Modern_Greek is 26\n",
      "distance between https://en.wikipedia.org/wiki/Special:Random and https://en.wikipedia.org/wiki/Philosophy is 15\n",
      "The search is too long, STOP!\n",
      "distance between https://en.wikipedia.org/wiki/Special:Random and https://en.wikipedia.org/wiki/Greek_language is 26\n",
      "That's All, Folks!\n"
     ]
    }
   ],
   "source": [
    "url_start = \"https://en.wikipedia.org/wiki/Mathematics\"\n",
    "url_stop = \"https://en.wikipedia.org/wiki/Philosophy\"\n",
    "urls = search_urls(url_start, url_stop)\n",
    "\n",
    "url_start = \"https://en.wikipedia.org/wiki/Molecular_biophysics\"\n",
    "urls = search_urls(url_start, url_stop)\n",
    "\n",
    "# Test on random URL\n",
    "print(\"Test on random URLs (/wiki/Special:Random)\")\n",
    "print(\"******************************************\")\n",
    "    \n",
    "url_start = \"https://en.wikipedia.org/wiki/Special:Random\"\n",
    "        \n",
    "for i in range(3):\n",
    "    urls = search_urls(url_start, url_stop)\n",
    "        \n",
    "    print(\"That's All, Folks!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
